{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MOF Screening using Active Learning #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from botorch.models import SingleTaskGP\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.acquisition.analytic import ExpectedImprovement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MOF</th>\n",
       "      <th>uptake_ads</th>\n",
       "      <th>uptake_des</th>\n",
       "      <th>heat_ads</th>\n",
       "      <th>heat_des</th>\n",
       "      <th>LISD</th>\n",
       "      <th>LFSD</th>\n",
       "      <th>LISFS</th>\n",
       "      <th>Unit_cell_volume</th>\n",
       "      <th>Density</th>\n",
       "      <th>...</th>\n",
       "      <th>O</th>\n",
       "      <th>La</th>\n",
       "      <th>Cr</th>\n",
       "      <th>Ti</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Rh</th>\n",
       "      <th>Ce</th>\n",
       "      <th>Cu</th>\n",
       "      <th>Al</th>\n",
       "      <th>Re</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XUKYEI_neutral</td>\n",
       "      <td>0.920997</td>\n",
       "      <td>0.668303</td>\n",
       "      <td>-21.55231</td>\n",
       "      <td>-18.39099</td>\n",
       "      <td>13.18217</td>\n",
       "      <td>10.20370</td>\n",
       "      <td>13.18217</td>\n",
       "      <td>6140.00</td>\n",
       "      <td>0.287208</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ja300034j_si_002_clean</td>\n",
       "      <td>0.433112</td>\n",
       "      <td>0.187346</td>\n",
       "      <td>-25.96441</td>\n",
       "      <td>-17.79542</td>\n",
       "      <td>17.49700</td>\n",
       "      <td>17.44104</td>\n",
       "      <td>17.49700</td>\n",
       "      <td>2800.68</td>\n",
       "      <td>0.713223</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QIYDAF01_clean</td>\n",
       "      <td>0.827077</td>\n",
       "      <td>0.660425</td>\n",
       "      <td>-19.37443</td>\n",
       "      <td>-18.95302</td>\n",
       "      <td>22.00141</td>\n",
       "      <td>13.48659</td>\n",
       "      <td>22.00141</td>\n",
       "      <td>52812.60</td>\n",
       "      <td>0.303251</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XAHPIH_clean</td>\n",
       "      <td>0.818678</td>\n",
       "      <td>0.634451</td>\n",
       "      <td>-21.96228</td>\n",
       "      <td>-19.54395</td>\n",
       "      <td>14.37026</td>\n",
       "      <td>13.22660</td>\n",
       "      <td>14.37026</td>\n",
       "      <td>12821.80</td>\n",
       "      <td>0.356183</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VETMIS_clean</td>\n",
       "      <td>0.932519</td>\n",
       "      <td>0.746597</td>\n",
       "      <td>-22.10557</td>\n",
       "      <td>-19.92746</td>\n",
       "      <td>18.13430</td>\n",
       "      <td>11.96931</td>\n",
       "      <td>18.13430</td>\n",
       "      <td>33152.20</td>\n",
       "      <td>0.311959</td>\n",
       "      <td>...</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      MOF  uptake_ads  uptake_des  heat_ads  heat_des  \\\n",
       "0          XUKYEI_neutral    0.920997    0.668303 -21.55231 -18.39099   \n",
       "1  ja300034j_si_002_clean    0.433112    0.187346 -25.96441 -17.79542   \n",
       "2          QIYDAF01_clean    0.827077    0.660425 -19.37443 -18.95302   \n",
       "3            XAHPIH_clean    0.818678    0.634451 -21.96228 -19.54395   \n",
       "4            VETMIS_clean    0.932519    0.746597 -22.10557 -19.92746   \n",
       "\n",
       "       LISD      LFSD     LISFS  Unit_cell_volume   Density  ...   O  La  Cr  \\\n",
       "0  13.18217  10.20370  13.18217           6140.00  0.287208  ...   0   0   0   \n",
       "1  17.49700  17.44104  17.49700           2800.68  0.713223  ...  18   0   0   \n",
       "2  22.00141  13.48659  22.00141          52812.60  0.303251  ...  96   0   0   \n",
       "3  14.37026  13.22660  14.37026          12821.80  0.356183  ...  40   0   0   \n",
       "4  18.13430  11.96931  18.13430          33152.20  0.311959  ...  48   0   0   \n",
       "\n",
       "   Ti  Ba  Rh  Ce  Cu  Al  Re  \n",
       "0   0   0   0   0   2   0   0  \n",
       "1   0   0   0   0   0   0   0  \n",
       "2   0   0   0   0  24   0   0  \n",
       "3   0   0   0   0   8   0   0  \n",
       "4   0   0   0   0  12   0   0  \n",
       "\n",
       "[5 rows x 111 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current working directory and read the csv file into the notebook\n",
    "PATH = os.getcwd()\n",
    "CSV_FILE = os.path.join(PATH, \"./Combined_set_prescreened (1).csv\");\n",
    "df = pd.read_csv(CSV_FILE);\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COP CALCULATION ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"deltaQ\"] = df[\"uptake_ads\"] - df[\"uptake_des\"]\n",
    "df[\"deltaHmean\"] = (df[\"heat_ads\"] + df[\"heat_des\"])/2\n",
    "df = df[df[\"deltaQ\"]>=0]\n",
    "deltaHvap = 16.25 \n",
    "Tads = 313.15 \n",
    "Tdes = 358.15\n",
    "Mw = 44.097/1000\n",
    "Cp = 1\n",
    "df[\"COP\"] = (deltaHvap * df[\"deltaQ\"]) / (Mw*Cp*(Tdes - Tads) - df[\"deltaHmean\"]*df[\"deltaQ\"]);\n",
    "df.drop(columns=[\"MOF\", \"uptake_ads\", \"uptake_des\", \"heat_ads\", \"heat_des\", \"deltaQ\", \"deltaHmean\"], inplace=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ACTIVE LEARNING CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "# Drop the column that is repeated\n",
    "df.drop(columns=[\"Number_of_pockets.1\"], inplace=True)\n",
    "# Drop the column that has only one unique value\n",
    "df.drop(columns=[\"Pu\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the 107 columns in the dataframe\n",
    "pd.set_option('display.max_columns', 108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LISD',\n",
       " 'LFSD',\n",
       " 'LISFS',\n",
       " 'Unit_cell_volume',\n",
       " 'Density',\n",
       " 'ASA_A2',\n",
       " 'ASA_m2_per_cm3',\n",
       " 'ASA_m2_per_g',\n",
       " 'NASA_A2',\n",
       " 'NASA_m2_per_cm3',\n",
       " 'NASA_m2_per_g',\n",
       " 'Number_of_channels',\n",
       " 'Channel_surface_area_A2',\n",
       " 'Number_of_pockets',\n",
       " 'AV_A3',\n",
       " 'AV_Volume_fraction',\n",
       " 'AV_cm3_per_g',\n",
       " 'NAV_A3',\n",
       " 'NAV_Volume_fraction',\n",
       " 'NAV_cm3_per_g',\n",
       " 'Channel_volume',\n",
       " 'oms_value',\n",
       " 'Pocket_volume_A3',\n",
       " 'Pocket_surface_area_A2',\n",
       " 'No_of_Channel',\n",
       " 'Di',\n",
       " 'Df',\n",
       " 'Dif',\n",
       " 'H',\n",
       " 'Yb',\n",
       " 'Ir',\n",
       " 'K',\n",
       " 'V',\n",
       " 'Te',\n",
       " 'Mn',\n",
       " 'Co',\n",
       " 'Sr',\n",
       " 'Bi',\n",
       " 'Cd',\n",
       " 'Mg',\n",
       " 'P',\n",
       " 'Be',\n",
       " 'Cl',\n",
       " 'As',\n",
       " 'F',\n",
       " 'Pb',\n",
       " 'Pr',\n",
       " 'Mo',\n",
       " 'I',\n",
       " 'Er',\n",
       " 'Fe',\n",
       " 'Y',\n",
       " 'W',\n",
       " 'Gd',\n",
       " 'Sn',\n",
       " 'Se',\n",
       " 'Cs',\n",
       " 'B',\n",
       " 'Ge',\n",
       " 'C',\n",
       " 'Si',\n",
       " 'Ag',\n",
       " 'Pt',\n",
       " 'S',\n",
       " 'Th',\n",
       " 'Ca',\n",
       " 'Dy',\n",
       " 'Au',\n",
       " 'Rb',\n",
       " 'Zr',\n",
       " 'Ho',\n",
       " 'Br',\n",
       " 'Sc',\n",
       " 'Na',\n",
       " 'U',\n",
       " 'Pd',\n",
       " 'Nd',\n",
       " 'Ni',\n",
       " 'Np',\n",
       " 'N',\n",
       " 'Nb',\n",
       " 'Ru',\n",
       " 'Li',\n",
       " 'Lu',\n",
       " 'Zn',\n",
       " 'Hg',\n",
       " 'Hf',\n",
       " 'Sb',\n",
       " 'In',\n",
       " 'Eu',\n",
       " 'Ga',\n",
       " 'Tb',\n",
       " 'Tm',\n",
       " 'Sm',\n",
       " 'O',\n",
       " 'La',\n",
       " 'Cr',\n",
       " 'Ti',\n",
       " 'Ba',\n",
       " 'Rh',\n",
       " 'Ce',\n",
       " 'Cu',\n",
       " 'Al',\n",
       " 'Re',\n",
       " 'COP']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the name of all the columns in the dataframe as a list\n",
    "features = df.columns.tolist()\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the feature matrix:  (6917, 104)\n",
      "Shape of the target matrix:  (6917,)\n"
     ]
    }
   ],
   "source": [
    "# Remove the COP column from the list of columns\n",
    "X = df[features[:-1]].values\n",
    "print(\"Shape of the feature matrix: \", X.shape)\n",
    "y = df[\"COP\"].values\n",
    "print(\"Shape of the target matrix: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data in X\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data from the numpy array to a tensor\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6917, 104]), torch.Size([6917]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the data\n",
    "X.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The forward function of Expected Improvement requires the input tensor [(b1xb2xb3....xbk)x1xd dim] and return tensor d dim\n",
    "X_unsqueezed = X.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Optimization Function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of MOFs in the dataset\n",
    "numberOfMOFs = 6917\n",
    "# Creating the Bayesian Optimazaition function\n",
    "def bayesianOptimizationFunction(numberOfIterations, numberOfSamples):\n",
    "    # Ensuring the number of iterations is greater than the number of samples so that model can be trained extensively\n",
    "    assert numberOfIterations > numberOfSamples\n",
    "    # Initial data points for the Bayesian Optimization\n",
    "    initialDataPoints = np.random.choice(numberOfMOFs, numberOfSamples, replace=False)\n",
    "    # Initial X and y values\n",
    "    initialY = y[initialDataPoints]\n",
    "    initialX = X[initialDataPoints]\n",
    "    for i in range(numberOfSamples, numberOfIterations):\n",
    "        # Create the model and the likelihood\n",
    "        model = SingleTaskGP(initialX, initialY)\n",
    "        modelLikelihood = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        fit_gpytorch_mll(modelLikelihood)\n",
    "        # Setting up the acquisition function\n",
    "        # `best_f`= Best function value observed\n",
    "        EI = ExpectedImprovement(model, best_f=initialY.max().item())\n",
    "        with torch.no_grad():\n",
    "            # Calculate the expected improvement uncertainity for dataset\n",
    "            newValues = EI.forward(X_unsqueezed)\n",
    "        # Arranging the indices in the descending order of expected improvement\n",
    "        newDataPoints = newValues.argsort(descending=True)\n",
    "        # Selecting datapoints which are initially not present\n",
    "        for dataPoint in newDataPoints:\n",
    "            if not dataPoint.item() in initialDataPoints:\n",
    "                newMaxDataPoint = dataPoint.item()\n",
    "                break\n",
    "        initialDataPoints = np.concatenate([initialDataPoints, [newMaxDataPoint]])\n",
    "        assert initialDataPoints.size == i+1\n",
    "        # Updating new datapoints to y and X\n",
    "        initialX = X[initialDataPoints]\n",
    "        initialY = y[initialDataPoints]\n",
    "    assert np.size(initialDataPoints) == numberOfIterations\n",
    "    return initialDataPoints\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "BotorchTensorDimensionError",
     "evalue": "An explicit output dimension is required for targets. Expected Y with dimension 2 (got Y.dim()=1).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBotorchTensorDimensionError\u001b[0m               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[43mbayesianOptimizationFunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 14\u001b[0m, in \u001b[0;36mbayesianOptimizationFunction\u001b[0;34m(numberOfIterations, numberOfSamples)\u001b[0m\n\u001b[1;32m     11\u001b[0m initialX \u001b[38;5;241m=\u001b[39m X[initialDataPoints]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(numberOfSamples, numberOfIterations):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# Create the model and the likelihood\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mSingleTaskGP\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitialX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitialY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     modelLikelihood \u001b[38;5;241m=\u001b[39m ExactMarginalLogLikelihood(model\u001b[38;5;241m.\u001b[39mlikelihood, model)\n\u001b[1;32m     16\u001b[0m     fit_gpytorch_mll(modelLikelihood)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/botorch/models/gp_regression.py:163\u001b[0m, in \u001b[0;36mSingleTaskGP.__init__\u001b[0;34m(self, train_X, train_Y, train_Yvar, likelihood, covar_module, mean_module, outcome_transform, input_transform)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outcome_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     train_Y, train_Yvar \u001b[38;5;241m=\u001b[39m outcome_transform(train_Y, train_Yvar)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tensor_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformed_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_Yvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m ignore_X_dims \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_ignore_X_dims_scaling_check\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    165\u001b[0m validate_input_scaling(\n\u001b[1;32m    166\u001b[0m     train_X\u001b[38;5;241m=\u001b[39mtransformed_X,\n\u001b[1;32m    167\u001b[0m     train_Y\u001b[38;5;241m=\u001b[39mtrain_Y,\n\u001b[1;32m    168\u001b[0m     train_Yvar\u001b[38;5;241m=\u001b[39mtrain_Yvar,\n\u001b[1;32m    169\u001b[0m     ignore_X_dims\u001b[38;5;241m=\u001b[39mignore_X_dims,\n\u001b[1;32m    170\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/botorch/models/gpytorch.py:105\u001b[0m, in \u001b[0;36mGPyTorchModel._validate_tensor_args\u001b[0;34m(X, Y, Yvar, strict)\u001b[0m\n\u001b[1;32m     99\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected X and Y to have the same number of dimensions\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m (got X with dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and Y with dimension\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mdim()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m     )\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strict:\n\u001b[0;32m--> 105\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BotorchTensorDimensionError(message)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNon-strict enforcement of botorch tensor conventions. The \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfollowing error would have been raised with strict enforcement: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    113\u001b[0m     )\n",
      "\u001b[0;31mBotorchTensorDimensionError\u001b[0m: An explicit output dimension is required for targets. Expected Y with dimension 2 (got Y.dim()=1)."
     ]
    }
   ],
   "source": [
    "index = bayesianOptimizationFunction(15, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
